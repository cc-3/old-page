---
layout: post
title:  "Laboratorio 6"
date:   2017-03-10
category: lab
description: >
    En este laboratorio van aprender una técnica de optimización y conocerán como se manejan los datos internamente. También tendrán la oportunidad de hacer algo relacionado con su proyecto 2.
---

### AVISO IMPORTANTE !

Ultimamente los auxiliares que califican sus labs han tenido problemas al ponerles sus notas ya que algunos de ustedes no envian su **LINK** del repositorio que se crea al **GES** y eso automaticamente es un **0** como nota, luego nos escriben en **slack** para que arreglemos su nota y hasta el momento los hemos considerado y les hemos tenido comprensión. Ahora es obligatorio que suban el link de su repositorio al GES una vez haya sido creado, porque nada les impide hacerlo. **Si ustedes no suben el link van a tener 0 en su laboratorio y no habrá oportunidad de que cambiemos su nota así que esten atentos y sean responsables con esto porfavor.**

#### Ejercicio 0: Subiendo mi link al GES

Este ejercicio es dummy y lo unico que tienen que hacer es subir su link del repositorio de una vez al GES (no hay puntos para este ejercicio pero nos evitamos un 0 como nota), para esto aqui está como siempre el [link](a) de **GitHub Classroom**. Cuando ya tengan subido al GES su link pueden seguir con el lab :+1:.

#### Ejercicio 1: Autograder Codificación Tipo R

Para este ejercicio lo que tienen que hacer es ver que tan bien van con su proyecto 2 de CC3 (ensamblador de Armv8), para esto **Carlos Hermosilla** ha creado un autograder que pueden obtener haciendo pull a su repositorio de **GitHub** del proyecto. Para obtener una calificación tienen que copiar lo que llevan de **ensamblador.s** al nuevo **ensambladorV2.s** compilar el autograder con gcc y por ultimo lo ejecutan para tener una puntuación.

```sh
$ gcc -o grading_r grading_r.c
$ ./grading_r
```

***

Vamos a cambiar el tema del lab que tenía que ver con su proyecto 2 y ahora
empezar a trabajar en C y cache optimization, la realidad es que es un tema
fascinante que muy pocas personas conocen, es tan util y como programadores
a ustedes los hace más valiosos si lo llegan a dominar perfectamente. :100:

#### Un poco de Información
<br>
**Multiplicación de Matrices**

Si se recuerdan, las matrices son estructuras de 2 dimensiones, donde uno tiene acceso a cada elemento vía 2 índices. Para multiplicar dos matrices, se puede utilizar simplemente 3 ciclos anidados, asumiendo que las matrices A, B y C son cuadradas (nxn) y están guardadas en un arreglo de una dimensión:

```c
for (int i = 0; i < n; i++)
    for (int j = 0; j < n; j++)
        for (int k = 0; k < n; k++)
            C[i+j*n] += A[i+k*n] * B[k+j*n];
```

La multiplicación de matrices son el core de muchos algoritmos de álgebra, y una multiplicación eficiente de matrices es crucial para muchas aplicaciones.

En el código de arriba, noten que los ciclos están ordenados por i, j, k. Si examinamos el ciclo interno (k), vemos que este se mueve a través de B con un paso igual a 1 (stride=1), a través de A con n pasos (stride=n) y a través de C con 0 pasos (stride=0). Para calcular la multiplicación de matrices correctamente, el orden de los ciclos no importa. Sin embargo, el orden en el que eligen acceder a los elementos de las matrices puede tener un mayor impacto en el performance del programa. El cache funciona mejor (hay mas cache hit, y menos cache misses) cuando se accede a la memoria tomando en cuenta la localidad temporal y espacial. Optimizar el acceso a memoria es esencial para obtener un buen performance en la jerarquía de memoria.

**Transponer Matrices**

Algunas veces, se necesita intercambiar en una matriz filas por columnas. A esto se le llama "transponer" y una implementación eficiente puede ser bien útil al utilizar operaciones de álgebra lineal más complicadas. La transpuesta de una matriz A se denota como A<sup>T</sup>.

![fig1](/assets/img/labs/matTnorm.png)

**Cache Blocking**

En el código de arriba de multiplicación de matrices, noten que para calcular un valor de C necesitamos atravesar las matrices A y B completamente. Nosotros estamos constantemente accediendo a valores nuevos de la memoria y reusando muy poco los datos que están en el cache. Podemos mejorar el reuso de esos datos en cache, implementando una técnica llamada cache blocking. Más formalmente, el cache blocking es una técnica que trata de reducir el “cache miss rate” mejorando la localidad temporal y/o espacial de los accesos a memoria. En el caso de la transpuesta de una matriz nosotros consideramos un bloque pequeño en cada tiempo.

![fig2](/assets/img/labs/matTblock.png)

En la imagen de arriba, nosotros transponemos cada bloque Aij de la matriz A a su posición final en la matriz de salida, un bloque a la vez. Con este esquema, nosotros podemos reducir el trabajo de llenar el cache durante el procesamiento de cualquier bloque. Esto (si está implementado correctamente) va resultar en un performance bastante significativo. En este lab van a implementar la técnica del cache blocking para calcular la transpuesta de una matriz y verificar su performance.

***

#### Ejercicio 2: Multiplicación de Matrices

Échenle un vistazo a **matrixMultiply.c**. Van a notar que el archivo contiene múltiples implementaciones de una multiplicación de matrices con 3 ciclos anidados. También sería interesante que ustedes traten de comprender que es lo que se escribió en ese archivo, tiene un par de features geniales de C que talvez no conocian.

Compilen y corran su código con el siguiente comando:

```shell
$ make ex2
```

Noten que el comando de compilación en el Makefile usa la bandera “-O3”. Es importante que aquí utilicemos la bandera “-O3” para que el compilador haga optimizaciones. El Makefile va a correr matrixMultiply dos veces. Copien los resultados en algún lugar para que ustedes no tengan que correr el programa otra vez y utilícenlos para responder a las siguientes preguntas:

Para responder lo que tienen que hacer es abrir el archivo ejercicio2.txt
y poner en cada linea la respuesta a cada pregunta, en este caso como son 4 preguntas el archivo tiene que tener solo 4 lineas y en cada linea una respuesta por ejemplo

```text
1
2
3
4
```

1. ¿Por qué el perfomance de Gflops/s baja con valores de n grandes?
    1. Porque el valor de n es inversamente proporcional a los GFLops/s.
    2. Así es la naturaleza de la multiplicación de matrices en una computadora.
    3. Van haber menos cache hits al no caber la matriz en el cache.
    4. Porque el cache funciona dinamicamente e inversamente proporcional a n, cuando n es muy grande su capacidad es menor.
2. ¿Qué orden de los ciclos tiene el mejor perfomance en las matrices de 1000x1000?
    1. ijk
    2. ikj
    3. jik
    4. jki
    5. kij
    6. kji
3. ¿Qué orden tiene el peor performance (1000x1000)?
    1. ijk
    2. ikj
    3. jik
    4. jki
    5. kij
    6. kji
4. ¿Cómo la manera en que avanzamos en las matrices con respecto al ciclo interno afecta el performance?
    1. La pregunta carece de sentido porque no importa nunca.
    2. El ciclo interno dictamina de que forma accedemos a memoria, row major or column major order.
    3. Solo importan los ciclos exteriores no el inner loop.

***

#### Ejercicio 3: Transpuesta de una Matriz

Compilen y corran la implementación (no muy buena) de la transpuesta de una matriz en transpose.c

```shell
$ make ex3
```

Lo siguiente, completar los siguientes ejercicios.

1. Noten el tiempo requerido para realizar la transpuesta de una matriz de tamaño 2000x2000
2. Modifiquen la función llamada tranpose en transpose.c para implementar un nivel de cache blocking. Esto es, hacer un ciclo que tome pequeños bloques de una matriz, a ese pequeño bloque hacerle la transpuesta y guardarlo en la matriz de destino. Asegúrense de manejar los casos especiales de la transpuesta: ¿Qué pasa si tratamos de aplicarle la transpuesta a una matriz de 5x5 con un tamaño de bloque de 2?
3. Prueben tamaños de bloque de 2x2, 100x100, 200x200, 400x400 y 1000x1000. ¿Cuál tiene la mejor performance en una matriz de 2000x2000? ¿Cuál tiene el peor performance? **Contesten cada pregunta en una linea en el archivo ejercicio3.txt**
4. Traten de correr su implementacion con un tamaño de bloque de 33 para la matriz de 1000x1000 y vean si funciona perfectamente
